{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491f4ee0",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 3 â€” Merge Prices & Sentiment, Build TA Features\n",
    "\n",
    "This notebook prepares the integrated daily panels per ticker:\n",
    "- **Prices** (Open, High, Low, Close, AdjClose, Volume)\n",
    "- **Technical indicators**: RSI(14), MACD(12,26,9), Signal, Histogram\n",
    "- **Aggregated sentiment** per day: mean s*, abs-max s*, news count\n",
    "- **Lagged sentiment features** for Chapter 4 (k = 0..2)\n",
    "- **Optional** market controls (SPY, XLK for AAPL; XLE for XOM; VIX placeholder)\n",
    "\n",
    "**Inputs (expected)**\n",
    "- Outputs of `02_sentiment_models.ipynb`: `./outputs/*_inference.csv`\n",
    "- Optional news CSVs with a `time` column for post-close mapping\n",
    "\n",
    "**Outputs**\n",
    "- `./outputs/panel_AAPL.csv`\n",
    "- `./outputs/panel_XOM.csv`\n",
    "- Figures (sanity checks) in `./figures/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2486be",
   "metadata": {},
   "source": [
    "## 0. Environment (Colab-friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d370126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running in Colab, uncomment:\n",
    "# !pip install -q yfinance==0.2.40 pandas==2.2.2 numpy==1.26.4 matplotlib==3.8.4\n",
    "# !pip install -q ta==0.11.0  # optional, we compute RSI/MACD manually anyway\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdec1e0",
   "metadata": {},
   "source": [
    "## 1. Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dee1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "OUT_DIR  = Path('./outputs')\n",
    "FIG_DIR  = Path('./figures')\n",
    "for d in [OUT_DIR, FIG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TICKERS = ['AAPL','XOM']\n",
    "MARKET_CONTROLS = {'SPY': 'SPY', 'XLK':'XLK', 'XLE':'XLE'}  # optional\n",
    "START = '2024-09-01'\n",
    "END   = '2024-12-31'\n",
    "\n",
    "print(\"Config OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf935c",
   "metadata": {},
   "source": [
    "## 2. Technical Indicators (RSI & MACD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deff73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_RSI(close: pd.Series, n:int=14) -> pd.Series:\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    gain = up.rolling(n, min_periods=n).mean()\n",
    "    loss = down.rolling(n, min_periods=n).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def compute_MACD(close: pd.Series, fast:int=12, slow:int=26, signal:int=9):\n",
    "    ema_fast = close.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = close.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    sig  = macd.ewm(span=signal, adjust=False).mean()\n",
    "    hist = macd - sig\n",
    "    return macd, sig, hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e9a80",
   "metadata": {},
   "source": [
    "## 3. Download Prices (AAPL/XOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_prices(ticker: str, start=START, end=END) -> pd.DataFrame:\n",
    "    df = yf.download(ticker, start=start, end=end, auto_adjust=False, progress=False)\n",
    "    # Flatten potential multiindex columns (defensive)\n",
    "    df.columns = ['_'.join(c) if isinstance(c, tuple) else c for c in df.columns]\n",
    "    # Standardize names\n",
    "    rename_map = {}\n",
    "    for c in df.columns:\n",
    "        base = c.split('_')[0].capitalize()\n",
    "        if base in ['Open','High','Low','Close','Volume']:\n",
    "            rename_map[c] = base\n",
    "        elif base == 'Adjclose' or c.lower().startswith('adj close'):\n",
    "            rename_map[c] = 'AdjClose'\n",
    "    df = df.rename(columns=rename_map).reset_index().rename(columns={'Date':'date'})\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date.astype(str)\n",
    "    # Indicators\n",
    "    df['RSI'] = compute_RSI(df['Close'])\n",
    "    macd, sig, hist = compute_MACD(df['Close'])\n",
    "    df['MACD'] = macd\n",
    "    df['Signal'] = sig\n",
    "    df['Hist'] = hist\n",
    "    df['ret'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['dRSI'] = df['RSI'].diff()\n",
    "    df['dMACD'] = df['MACD'].diff()\n",
    "    df['ticker'] = ticker\n",
    "    return df\n",
    "\n",
    "prices = {t: load_prices(t) for t in TICKERS}\n",
    "{t: prices[t].head(3) for t in TICKERS}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5fb70",
   "metadata": {},
   "source": [
    "## 4. Load Sentiment Inference & Aggregate by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from glob import glob\n",
    "\n",
    "def find_inference_files():\n",
    "    files = glob(str(OUT_DIR / \"*_inference.csv\"))\n",
    "    return files\n",
    "\n",
    "def aggregate_daily(inf_csv: Path) -> pd.DataFrame:\n",
    "    dfp = pd.read_csv(inf_csv)\n",
    "    # Build signed confidence s*\n",
    "    def signed_strength(row):\n",
    "        pred = row['pred']\n",
    "        sign = -1 if pred=='negative' else (1 if pred=='positive' else 0)\n",
    "        strength = max(row['proba_negative'], row['proba_neutral'], row['proba_positive'])\n",
    "        return sign * strength\n",
    "\n",
    "    dfp['s_star'] = dfp.apply(signed_strength, axis=1)\n",
    "    daily = (dfp.groupby(['date','ticker'], as_index=False)\n",
    "                .agg(s_mean=('s_star','mean'),\n",
    "                     s_absmax=('s_star', lambda x: np.abs(x).max()),\n",
    "                     n_news=('s_star','size')))\n",
    "    daily['date'] = pd.to_datetime(daily['date']).dt.date.astype(str)\n",
    "    return daily\n",
    "\n",
    "inf_files = find_inference_files()\n",
    "print(\"Found inference files:\", inf_files)\n",
    "daily_agg = {}\n",
    "for f in inf_files:\n",
    "    name = Path(f).stem.replace('_inference','')\n",
    "    daily_agg[name] = aggregate_daily(Path(f))\n",
    "\n",
    "# Prefer FinBERT aggregation if available; else fall back to any\n",
    "PREFERRED = 'finbert-prosus'\n",
    "if PREFERRED in daily_agg:\n",
    "    news_daily = daily_agg[PREFERRED]\n",
    "else:\n",
    "    # take the first available\n",
    "    k = list(daily_agg.keys())[0] if daily_agg else None\n",
    "    news_daily = daily_agg.get(k, pd.DataFrame(columns=['date','ticker','s_mean','s_absmax','n_news']))\n",
    "news_daily.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84438154",
   "metadata": {},
   "source": [
    "## 5. Optional: Post-Close Mapping (if time is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If your raw news CSVs include 'time' (HH:MM in exchange TZ), you can remap post-close news to T+1.\n",
    "# Here we provide a placeholder function. Adjust 'close_hour' per exchange if needed.\n",
    "def map_to_trading_date(date_str: str, time_str: str, close_hour:int=16) -> str:\n",
    "    dt = pd.to_datetime(f\"{date_str} {time_str}\")\n",
    "    if dt.hour >= close_hour:\n",
    "        return (dt + pd.Timedelta(days=1)).date().astype(str)\n",
    "    return dt.date().astype(str)\n",
    "\n",
    "# In this notebook we assume inference files already have 'date' aligned to trading date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ad811",
   "metadata": {},
   "source": [
    "## 6. Merge Prices + Sentiment by Trading Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_panel(df_prices: pd.DataFrame, df_news_daily: pd.DataFrame) -> pd.DataFrame:\n",
    "    m = df_prices.merge(df_news_daily, on=['date','ticker'], how='left')\n",
    "    # Fill missing sentiment with neutral zeros\n",
    "    m[['s_mean','s_absmax','n_news']] = m[['s_mean','s_absmax','n_news']].fillna({'s_mean':0.0,'s_absmax':0.0,'n_news':0})\n",
    "    # Lags for Chapter 4\n",
    "    for k in [0,1,2]:\n",
    "        m[f's_mean_lag{k}'] = m['s_mean'].shift(k)\n",
    "        m[f's_absmax_lag{k}'] = m['s_absmax'].shift(k)\n",
    "        m[f'n_news_lag{k}'] = m['n_news'].shift(k)\n",
    "    # Drop initial NaNs from lags at export time (user can also leave them)\n",
    "    return m\n",
    "\n",
    "panel = {}\n",
    "for t in TICKERS:\n",
    "    p = prices[t].copy()\n",
    "    news_t = news_daily[news_daily['ticker']==t].copy()\n",
    "    panel[t] = merge_panel(p, news_t)\n",
    "    outp = OUT_DIR / f'panel_{t}.csv'\n",
    "    panel[t].to_csv(outp, index=False)\n",
    "    print(\"[Saved]\", outp)\n",
    "\n",
    "panel['AAPL'].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c3ee2",
   "metadata": {},
   "source": [
    "## 7. (Optional) Market Controls (SPY/XLK/XLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_controls(panel_df: pd.DataFrame, ctrl_ticker: str, col_prefix:str) -> pd.DataFrame:\n",
    "    ctrl = yf.download(ctrl_ticker, start=START, end=END, progress=False)\n",
    "    ctrl = ctrl.rename(columns={'Adj Close':'AdjClose'}).reset_index().rename(columns={'Date':'date'})\n",
    "    ctrl['date'] = pd.to_datetime(ctrl['date']).dt.date.astype(str)\n",
    "    ctrl['ret_ctrl'] = np.log(ctrl['AdjClose'] / ctrl['AdjClose'].shift(1))\n",
    "    ctrl = ctrl[['date','ret_ctrl']]\n",
    "    out = panel_df.merge(ctrl, on='date', how='left')\n",
    "    out = out.rename(columns={'ret_ctrl': f'{col_prefix}_ret'})\n",
    "    return out\n",
    "\n",
    "# Example: add SPY to both; XLK for AAPL, XLE for XOM\n",
    "panel['AAPL'] = add_controls(panel['AAPL'], 'SPY', 'SPY')\n",
    "panel['AAPL'] = add_controls(panel['AAPL'], 'XLK', 'Sector')\n",
    "panel['XOM']  = add_controls(panel['XOM'],  'SPY', 'SPY')\n",
    "panel['XOM']  = add_controls(panel['XOM'],  'XLE', 'Sector')\n",
    "\n",
    "# Save updated panels\n",
    "for t in TICKERS:\n",
    "    outp = OUT_DIR / f'panel_{t}.csv'\n",
    "    panel[t].to_csv(outp, index=False)\n",
    "    print(\"[Updated]\", outp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e2571",
   "metadata": {},
   "source": [
    "## 8. Sanity-Check Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sanity_plot(panel_df: pd.DataFrame, ticker:str, fig_path:Path):\n",
    "    fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "    ax1.plot(pd.to_datetime(panel_df['date']), panel_df['Close'])\n",
    "    ax1.set_title(f'{ticker}: Close with daily sentiment markers')\n",
    "    ax1.set_xlabel('Date'); ax1.set_ylabel('Close')\n",
    "    # sentiment markers (size by |s_mean|, color omitted by guideline; default used)\n",
    "    dates = pd.to_datetime(panel_df['date'])\n",
    "    sizes = (panel_df['s_absmax'].abs().fillna(0.0) * 200) + 10\n",
    "    ax1.scatter(dates, panel_df['Close'], s=sizes)\n",
    "    ax1.grid(True); fig.tight_layout()\n",
    "    fig.savefig(fig_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "sanity_plot(panel['AAPL'], 'AAPL', FIG_DIR/'AAPL_close_sentiment.png')\n",
    "sanity_plot(panel['XOM'],  'XOM',  FIG_DIR/'XOM_close_sentiment.png')\n",
    "print(\"Saved sanity plots to ./figures\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}