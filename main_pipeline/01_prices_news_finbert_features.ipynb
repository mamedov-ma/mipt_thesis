{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0017a6e",
   "metadata": {},
   "source": [
    "# Notebook 1 — Prices (AAPL, XOM) + News → FinBERT → Daily sentiment index `I_t` + Features\n",
    "\n",
    "Что делает ноутбук:\n",
    "\n",
    "1) скачивает дневные OHLCV за последние **5 лет** (можно поменять `YEARS_BACK`);  \n",
    "2) скачивает новости (по умолчанию **Alpha Vantage News & Sentiment**; нужен API key; есть fallback на GDELT, но у него ограничение по истории);  \n",
    "3) прогоняет тексты новостей через **FinBERT (ProsusAI/finbert)**, считает `s(x)` и дневной индекс `I_t`;  \n",
    "4) считает `returns`, `RSI`, `MACD`;  \n",
    "5) собирает финальную таблицу `date, returns, RSI, MACD, I_t` (и сохраняет в файлы).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89107fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayil/Desktop/mipt_master_thesis/py/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies look installed.\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, importlib\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs)\n",
    "\n",
    "required = [\n",
    "    \"pandas>=2.0\", \"numpy>=1.24\", \"requests>=2.31\", \"tqdm>=4.66\",\n",
    "    \"yfinance>=0.2.30\",\n",
    "    \"transformers>=4.40\", \"torch\",  # torch может быть уже установлен\n",
    "    \"pyarrow>=14.0\",  # для parquet\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for pkg in [\"pandas\",\"numpy\",\"requests\",\"tqdm\",\"yfinance\",\"transformers\",\"torch\",\"pyarrow\"]:\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except Exception:\n",
    "        missing.append(pkg)\n",
    "\n",
    "if missing:\n",
    "    print(\"Installing missing:\", missing)\n",
    "    pip_install(required)\n",
    "else:\n",
    "    print(\"All dependencies look installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4aa4498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2020-12-28 → 2025-12-28\n"
     ]
    }
   ],
   "source": [
    "import os, math, time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TICKERS = [\"AAPL\", \"XOM\"]\n",
    "YEARS_BACK = 5  # поменяйте на 3..5 по задаче\n",
    "\n",
    "END_DATE = pd.Timestamp.utcnow().normalize()\n",
    "START_DATE = END_DATE - pd.DateOffset(years=YEARS_BACK)\n",
    "\n",
    "print(\"Date range:\", START_DATE.date(), \"→\", END_DATE.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cecdfc9",
   "metadata": {},
   "source": [
    "## 1) Данные по ценам (daily OHLCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet engine: fastparquet\n",
      "AAPL (1256, 8) 2020-12-28 2025-12-26 -> prices_AAPL.parquet\n",
      "XOM (1256, 8) 2020-12-28 2025-12-26 -> prices_XOM.parquet\n",
      "Saved: data/prices_all.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapl</th>\n",
       "      <th></th>\n",
       "      <th>xom</th>\n",
       "      <th>xom</th>\n",
       "      <th>xom</th>\n",
       "      <th>xom</th>\n",
       "      <th>xom</th>\n",
       "      <th>xom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>137.339996</td>\n",
       "      <td>133.509995</td>\n",
       "      <td>136.690002</td>\n",
       "      <td>133.061218</td>\n",
       "      <td>124486200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>131.289520</td>\n",
       "      <td>121047300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>135.580002</td>\n",
       "      <td>135.990005</td>\n",
       "      <td>133.399994</td>\n",
       "      <td>133.720001</td>\n",
       "      <td>130.170029</td>\n",
       "      <td>96452100.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>134.080002</td>\n",
       "      <td>134.740005</td>\n",
       "      <td>131.720001</td>\n",
       "      <td>132.690002</td>\n",
       "      <td>129.167374</td>\n",
       "      <td>99116600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>133.610001</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>125.974480</td>\n",
       "      <td>143301900.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        date        open        high         low       close   adj close  \\\n",
       "Ticker                   aapl        aapl        aapl        aapl        aapl   \n",
       "0      2020-12-28  133.990005  137.339996  133.509995  136.690002  133.061218   \n",
       "1      2020-12-29  138.050003  138.789993  134.339996  134.869995  131.289520   \n",
       "2      2020-12-30  135.580002  135.990005  133.399994  133.720001  130.170029   \n",
       "3      2020-12-31  134.080002  134.740005  131.720001  132.690002  129.167374   \n",
       "4      2021-01-04  133.520004  133.610001  126.760002  129.410004  125.974480   \n",
       "\n",
       "Price        volume ticker open high low close adj close volume  \n",
       "Ticker         aapl         xom  xom xom   xom       xom    xom  \n",
       "0       124486200.0   AAPL  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "1       121047300.0   AAPL  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "2        96452100.0   AAPL  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "3        99116600.0   AAPL  NaN  NaN NaN   NaN       NaN    NaN  \n",
       "4       143301900.0   AAPL  NaN  NaN NaN   NaN       NaN    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# --- 0) DATA_DIR (на всякий случай) ---\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1) Выбор engine: fastparquet -> предпочтительно ---\n",
    "_PARQUET_ENGINE = None\n",
    "try:\n",
    "    import fastparquet  # noqa: F401\n",
    "    _PARQUET_ENGINE = \"fastparquet\"\n",
    "    print(\"Parquet engine:\", _PARQUET_ENGINE)\n",
    "except Exception:\n",
    "    _PARQUET_ENGINE = \"pyarrow\"\n",
    "    print(\"Parquet engine:\", _PARQUET_ENGINE, \"(fastparquet not found)\")\n",
    "\n",
    "# --- 2) Safe Parquet writer ---\n",
    "def _reset_pyarrow_pandas_ext_types():\n",
    "    # безопасно: если pyarrow нет/другая версия — просто пропустим\n",
    "    try:\n",
    "        import pyarrow as pa\n",
    "    except Exception:\n",
    "        return\n",
    "\n",
    "    # точечные самые частые\n",
    "    for name in (\"pandas.period\", \"pandas.interval\"):\n",
    "        try:\n",
    "            pa.unregister_extension_type(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # попытка подчистить всё pandas.* если API доступен\n",
    "    for attr in (\"registered_extension_types\", \"get_registered_extension_types\", \"list_registered_extension_types\"):\n",
    "        try:\n",
    "            fn = getattr(pa, attr)\n",
    "        except Exception:\n",
    "            continue\n",
    "        try:\n",
    "            reg = fn()\n",
    "            # pyarrow может вернуть dict или list\n",
    "            if isinstance(reg, dict):\n",
    "                names = list(reg.keys())\n",
    "            else:\n",
    "                names = list(reg)\n",
    "            for n in names:\n",
    "                n = str(n)\n",
    "                if n.startswith(\"pandas.\"):\n",
    "                    try:\n",
    "                        pa.unregister_extension_type(n)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "def safe_to_parquet(df: pd.DataFrame, path, engine: str):\n",
    "    \"\"\"\n",
    "    Пишем Parquet устойчиво.\n",
    "    - Если ловим ArrowKeyError про pandas.* already defined — чистим registry и повторяем 1 раз.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_parquet(path, index=False, engine=engine)\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        if (\"type extension with name pandas.\" in msg and \"already defined\" in msg) or \"ArrowKeyError\" in msg:\n",
    "            _reset_pyarrow_pandas_ext_types()\n",
    "            df.to_parquet(path, index=False, engine=engine)  # retry once\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def download_prices(ticker: str, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:\n",
    "    df = yf.download(\n",
    "        ticker, start=start.date(), end=(end + pd.Timedelta(days=1)).date(),\n",
    "        interval=\"1d\", auto_adjust=False, progress=False\n",
    "    )\n",
    "    if df.empty:\n",
    "        raise RuntimeError(f\"No price data for {ticker}\")\n",
    "    df = df.rename(columns=str.lower)\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df = df.reset_index().rename(columns={\"Date\":\"date\", \"index\":\"date\"})\n",
    "    df[\"ticker\"] = ticker\n",
    "    return df[[\"date\",\"open\",\"high\",\"low\",\"close\",\"adj close\",\"volume\",\"ticker\"]]\n",
    "\n",
    "# --- 3) Скачивание и сохранение ---\n",
    "prices_list = []\n",
    "\n",
    "for t in TICKERS:\n",
    "    dft = download_prices(t, START_DATE, END_DATE)  # ваша функция из предыдущей ячейки\n",
    "    prices_list.append(dft)\n",
    "\n",
    "    out_path = DATA_DIR / f\"prices_{t}.parquet\"\n",
    "    safe_to_parquet(dft, out_path, engine=_PARQUET_ENGINE)\n",
    "\n",
    "    print(\n",
    "        t,\n",
    "        dft.shape,\n",
    "        dft[\"date\"].min().date(),\n",
    "        dft[\"date\"].max().date(),\n",
    "        \"->\",\n",
    "        out_path.name,\n",
    "    )\n",
    "\n",
    "prices = pd.concat(prices_list, ignore_index=True)\n",
    "\n",
    "all_path = DATA_DIR / \"prices_all.parquet\"\n",
    "safe_to_parquet(prices, all_path, engine=_PARQUET_ENGINE)\n",
    "print(\"Saved:\", all_path)\n",
    "\n",
    "prices.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae347649",
   "metadata": {},
   "source": [
    "## 2) Новости + маппинг по датам\n",
    "\n",
    "### Источник новостей\n",
    "- **Основной (рекомендуется): Alpha Vantage `NEWS_SENTIMENT`** — поддерживает `time_from/time_to` (можно брать 3–5 лет), но нужен API key. citeturn3view0  \n",
    "- **Fallback: GDELT DOC API** — без ключа, но по сути ограничен коротким окном истории (не подойдет для 3–5 лет). citeturn1view0\n",
    "\n",
    "В коде ниже:\n",
    "- если `ALPHAVANTAGE_API_KEY` задан, используем Alpha Vantage;\n",
    "- иначе используем GDELT на коротком промежутке (чтобы ноутбук всё равно работал)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45866962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_ALPHA_VANTAGE = True\n"
     ]
    }
   ],
   "source": [
    "# TB228JYIOYDWU5Q9\n",
    "\n",
    "ALPHAVANTAGE_API_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\", \"\").strip()\n",
    "ALPHAVANTAGE_API_KEY=\"TB228JYIOYDWU5Q9\"\n",
    "USE_ALPHA_VANTAGE = bool(ALPHAVANTAGE_API_KEY)\n",
    "\n",
    "\n",
    "print(\"USE_ALPHA_VANTAGE =\", USE_ALPHA_VANTAGE)\n",
    "if not USE_ALPHA_VANTAGE:\n",
    "    print(\"⚠️  Нет ALPHAVANTAGE_API_KEY. Будет fallback на GDELT (ограниченная история).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e96363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yyyymmddThhmm(ts: pd.Timestamp) -> str:\n",
    "    # Alpha Vantage: YYYYMMDDTHHMM (UTC)\n",
    "    ts = ts.tz_localize(timezone.utc) if ts.tzinfo is None else ts.tz_convert(timezone.utc)\n",
    "    return ts.strftime(\"%Y%m%dT%H%M\")\n",
    "\n",
    "def alpha_vantage_news_window(ticker: str, time_from: pd.Timestamp, time_to: pd.Timestamp, limit: int = 1000, sort: str=\"EARLIEST\") -> pd.DataFrame:\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"tickers\": ticker,\n",
    "        \"time_from\": yyyymmddThhmm(time_from),\n",
    "        \"time_to\": yyyymmddThhmm(time_to),\n",
    "        \"limit\": limit,\n",
    "        \"sort\": sort,\n",
    "        \"apikey\": ALPHAVANTAGE_API_KEY,\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    # возможные ошибки: {'Information': '...'} / {'Note': '...'}\n",
    "    if \"feed\" not in data:\n",
    "        raise RuntimeError(f\"Alpha Vantage response without 'feed': {list(data.keys())}\")\n",
    "\n",
    "    rows = []\n",
    "    for it in data[\"feed\"]:\n",
    "        rows.append({\n",
    "            \"ticker\": ticker,\n",
    "            \"time_published\": it.get(\"time_published\"),\n",
    "            \"title\": it.get(\"title\"),\n",
    "            \"summary\": it.get(\"summary\"),\n",
    "            \"url\": it.get(\"url\"),\n",
    "            \"source\": it.get(\"source\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def fetch_alpha_vantage_news(ticker: str, start: pd.Timestamp, end: pd.Timestamp, window_days: int = 30) -> pd.DataFrame:\n",
    "    # chunk по окнам, чтобы не упираться в limit и проще переживать rate-limit\n",
    "    all_parts = []\n",
    "    cur = start\n",
    "    pbar = tqdm(total=int((end-start).days/window_days)+1, desc=f\"AV news {ticker}\")\n",
    "    while cur < end:\n",
    "        nxt = min(cur + pd.Timedelta(days=window_days), end)\n",
    "        try:\n",
    "            part = alpha_vantage_news_window(ticker, cur, nxt, limit=1000, sort=\"EARLIEST\")\n",
    "            all_parts.append(part)\n",
    "        except Exception as e:\n",
    "            print(\"Window failed:\", cur.date(), \"→\", nxt.date(), \":\", repr(e))\n",
    "        # free-tier rate limit обычно 5 запросов/мин → пауза; при необходимости уменьшите\n",
    "        time.sleep(12)\n",
    "        cur = nxt\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    if not all_parts:\n",
    "        return pd.DataFrame(columns=[\"ticker\",\"time_published\",\"title\",\"summary\",\"url\",\"source\"])\n",
    "\n",
    "    df = pd.concat(all_parts, ignore_index=True).drop_duplicates(subset=[\"url\"])\n",
    "    return df\n",
    "\n",
    "# GDELT fallback (короткое окно истории)\n",
    "def fetch_gdelt_artlist(query: str, timespan: str = \"3m\", maxrecords: int = 250) -> pd.DataFrame:\n",
    "    url = \"https://api.gdeltproject.org/api/v2/doc/doc\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"mode\": \"artlist\",\n",
    "        \"format\": \"json\",\n",
    "        \"timespan\": timespan,\n",
    "        \"maxrecords\": maxrecords,\n",
    "        \"sort\": \"datedesc\",\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    arts = data.get(\"articles\", [])\n",
    "    rows = []\n",
    "    for a in arts:\n",
    "        rows.append({\n",
    "            \"time_published\": a.get(\"seendate\"),\n",
    "            \"title\": a.get(\"title\"),\n",
    "            \"summary\": a.get(\"snippet\"),\n",
    "            \"url\": a.get(\"url\"),\n",
    "            \"source\": a.get(\"sourceCountry\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528dbe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet engine: fastparquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AV news AAPL: 100%|██████████| 61/61 [13:18<00:00, 13.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: news_raw_AAPL.parquet (3503, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AV news XOM: 100%|██████████| 61/61 [13:07<00:00, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: news_raw_XOM.parquet (2652, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>time_published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201229T125600</td>\n",
       "      <td>Intel shares rise after Third Point urges chip...</td>\n",
       "      <td>Hedge fund Third Point, which recently acquire...</td>\n",
       "      <td>https://www.cnbc.com/2020/12/29/third-point-ur...</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>2020-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201230T022400</td>\n",
       "      <td>Exclusive: Hedge fund Third Point urges Intel ...</td>\n",
       "      <td>Activist hedge fund Third Point LLC, which has...</td>\n",
       "      <td>https://www.reuters.com/business/retail-consum...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2020-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201230T052800</td>\n",
       "      <td>Apple loses copyright claims in lawsuit agains...</td>\n",
       "      <td>A federal judge in Florida dismissed Apple Inc...</td>\n",
       "      <td>https://www.reuters.com/business/apple-loses-c...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2020-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20210104T120000</td>\n",
       "      <td>Apple Veterans’ Lidar Startup Adds $200 Millio...</td>\n",
       "      <td>Aeva, a lidar startup founded by former Apple ...</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2021-0...</td>\n",
       "      <td>Bloomberg.com</td>\n",
       "      <td>2021-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20210104T212202</td>\n",
       "      <td>The TDVG ETF Is a Stellar Choice for Dividend ...</td>\n",
       "      <td>The TDVG ETF is highlighted as a strong option...</td>\n",
       "      <td>https://etfdb.com/active-etf-channel/tdvg-etf-...</td>\n",
       "      <td>ETF Database</td>\n",
       "      <td>2021-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker   time_published                                              title  \\\n",
       "0   AAPL  20201229T125600  Intel shares rise after Third Point urges chip...   \n",
       "1   AAPL  20201230T022400  Exclusive: Hedge fund Third Point urges Intel ...   \n",
       "2   AAPL  20201230T052800  Apple loses copyright claims in lawsuit agains...   \n",
       "3   AAPL  20210104T120000  Apple Veterans’ Lidar Startup Adds $200 Millio...   \n",
       "4   AAPL  20210104T212202  The TDVG ETF Is a Stellar Choice for Dividend ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hedge fund Third Point, which recently acquire...   \n",
       "1  Activist hedge fund Third Point LLC, which has...   \n",
       "2  A federal judge in Florida dismissed Apple Inc...   \n",
       "3  Aeva, a lidar startup founded by former Apple ...   \n",
       "4  The TDVG ETF is highlighted as a strong option...   \n",
       "\n",
       "                                                 url         source       date  \n",
       "0  https://www.cnbc.com/2020/12/29/third-point-ur...           CNBC 2020-12-29  \n",
       "1  https://www.reuters.com/business/retail-consum...        Reuters 2020-12-30  \n",
       "2  https://www.reuters.com/business/apple-loses-c...        Reuters 2020-12-30  \n",
       "3  https://www.bloomberg.com/news/articles/2021-0...  Bloomberg.com 2021-01-04  \n",
       "4  https://etfdb.com/active-etf-channel/tdvg-etf-...   ETF Database 2021-01-04  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1) Выбор движка Parquet (fastparquet -> надёжнее, иначе pyarrow + reset) ---\n",
    "_PARQUET_ENGINE = None\n",
    "try:\n",
    "    import fastparquet  # noqa: F401\n",
    "    _PARQUET_ENGINE = \"fastparquet\"\n",
    "except Exception:\n",
    "    _PARQUET_ENGINE = \"pyarrow\"\n",
    "\n",
    "def _reset_pyarrow_pandas_ext_types():\n",
    "    try:\n",
    "        import pyarrow as pa\n",
    "    except Exception:\n",
    "        return\n",
    "\n",
    "    # Частые конфликтующие типы\n",
    "    for name in (\"pandas.period\", \"pandas.interval\"):\n",
    "        try:\n",
    "            pa.unregister_extension_type(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Попытка удалить всё pandas.* если API доступен\n",
    "    for attr in (\"registered_extension_types\", \"get_registered_extension_types\", \"list_registered_extension_types\"):\n",
    "        try:\n",
    "            fn = getattr(pa, attr)\n",
    "        except Exception:\n",
    "            continue\n",
    "        try:\n",
    "            reg = fn()\n",
    "            names = list(reg.keys()) if isinstance(reg, dict) else list(reg)\n",
    "            for n in names:\n",
    "                n = str(n)\n",
    "                if n.startswith(\"pandas.\"):\n",
    "                    try:\n",
    "                        pa.unregister_extension_type(n)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def safe_to_parquet(df: pd.DataFrame, path):\n",
    "    try:\n",
    "        df.to_parquet(path, index=False, engine=_PARQUET_ENGINE)\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        if (\"type extension with name pandas.\" in msg and \"already defined\" in msg) or \"ArrowKeyError\" in msg:\n",
    "            _reset_pyarrow_pandas_ext_types()\n",
    "            df.to_parquet(path, index=False, engine=_PARQUET_ENGINE)  # retry once\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def safe_read_parquet(path) -> pd.DataFrame:\n",
    "    # чтение обычно не падает, но пусть будет симметрично\n",
    "    return pd.read_parquet(path, engine=_PARQUET_ENGINE)\n",
    "\n",
    "print(\"Parquet engine:\", _PARQUET_ENGINE)\n",
    "\n",
    "\n",
    "# --- 2) Нормальный парсер time_published ---\n",
    "def to_date_from_time_published(s) -> pd.Timestamp:\n",
    "    # Alpha Vantage: YYYYMMDDTHHMMSS ; GDELT often: YYYYMMDDHHMMSS or variations\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return pd.NaT\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return pd.NaT\n",
    "\n",
    "    try:\n",
    "        if \"T\" in s and len(s) >= 15:  # 20240131T235959\n",
    "            dt = pd.to_datetime(s[:15], format=\"%Y%m%dT%H%M%S\", utc=True, errors=\"coerce\")\n",
    "        elif len(s) >= 14:  # 20240131235959\n",
    "            dt = pd.to_datetime(s[:14], format=\"%Y%m%d%H%M%S\", utc=True, errors=\"coerce\")\n",
    "        elif len(s) >= 12:  # 202401312359\n",
    "            dt = pd.to_datetime(s[:12], format=\"%Y%m%d%H%M\", utc=True, errors=\"coerce\")\n",
    "        else:\n",
    "            dt = pd.to_datetime(s, utc=True, errors=\"coerce\")\n",
    "    except Exception:\n",
    "        dt = pd.NaT\n",
    "\n",
    "    if pd.isna(dt):\n",
    "        return pd.NaT\n",
    "    return dt.tz_convert(None).normalize()\n",
    "\n",
    "\n",
    "# --- 3) Загрузка/кеширование новостей ---\n",
    "news_all = []\n",
    "\n",
    "for t in TICKERS:\n",
    "    out_path = DATA_DIR / f\"news_raw_{t}.parquet\"\n",
    "\n",
    "    if out_path.exists():\n",
    "        df = safe_read_parquet(out_path)\n",
    "        print(\"Loaded cached:\", out_path.name, df.shape)\n",
    "    else:\n",
    "        if USE_ALPHA_VANTAGE:\n",
    "            df = fetch_alpha_vantage_news(t, START_DATE, END_DATE, window_days=30)\n",
    "        else:\n",
    "            # fallback: запрос по тикеру как по ключевому слову (ограничение истории)\n",
    "            df = fetch_gdelt_artlist(query=t, timespan=\"3m\", maxrecords=250)\n",
    "\n",
    "        # гарантируем ticker\n",
    "        df[\"ticker\"] = t\n",
    "\n",
    "        # гарантируем expected columns (на случай разной схемы источников)\n",
    "        for col in (\"time_published\", \"title\", \"url\"):\n",
    "            if col not in df.columns:\n",
    "                df[col] = pd.NA\n",
    "\n",
    "        df[\"date\"] = df[\"time_published\"].apply(to_date_from_time_published)\n",
    "\n",
    "        # чистка\n",
    "        df = df.dropna(subset=[\"date\", \"title\"]).copy()\n",
    "        if \"url\" in df.columns and df[\"url\"].notna().any():\n",
    "            df = df.drop_duplicates(subset=[\"url\"])\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"title\", \"date\", \"ticker\"])\n",
    "\n",
    "        safe_to_parquet(df, out_path)\n",
    "        print(\"Saved:\", out_path.name, df.shape)\n",
    "\n",
    "    news_all.append(df)\n",
    "\n",
    "news_all = pd.concat(news_all, ignore_index=True)\n",
    "news_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d874d347",
   "metadata": {},
   "source": [
    "## 3) FinBERT → `s(x)` и дневной индекс `I_t`\n",
    "\n",
    "Модель: **ProsusAI/finbert** (3 класса: positive/negative/neutral). citeturn0search1  \n",
    "\n",
    "Считаем для каждой новости:\n",
    "\n",
    "- `p_pos, p_neg, p_neu` — softmax вероятности\n",
    "- `s(x) = p_pos - p_neg` (в диапазоне [-1, 1]) — удобная непрерывная метрика citeturn0search13\n",
    "\n",
    "Далее агрегируем по дню и тикеру:\n",
    "\n",
    "- `I_t = mean(s(x))` по всем новостям в этот день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa55282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "labels: {0: 'positive', 1: 'negative', 2: 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"device:\", device)\n",
    "print(\"labels:\", model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2da302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News rows: 6155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>time_published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201229T125600</td>\n",
       "      <td>Intel shares rise after Third Point urges chip...</td>\n",
       "      <td>Hedge fund Third Point, which recently acquire...</td>\n",
       "      <td>https://www.cnbc.com/2020/12/29/third-point-ur...</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>Intel shares rise after Third Point urges chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201230T052800</td>\n",
       "      <td>Apple loses copyright claims in lawsuit agains...</td>\n",
       "      <td>A federal judge in Florida dismissed Apple Inc...</td>\n",
       "      <td>https://www.reuters.com/business/apple-loses-c...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>Apple loses copyright claims in lawsuit agains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201230T022400</td>\n",
       "      <td>Exclusive: Hedge fund Third Point urges Intel ...</td>\n",
       "      <td>Activist hedge fund Third Point LLC, which has...</td>\n",
       "      <td>https://www.reuters.com/business/retail-consum...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>Exclusive: Hedge fund Third Point urges Intel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20210104T212202</td>\n",
       "      <td>The TDVG ETF Is a Stellar Choice for Dividend ...</td>\n",
       "      <td>The TDVG ETF is highlighted as a strong option...</td>\n",
       "      <td>https://etfdb.com/active-etf-channel/tdvg-etf-...</td>\n",
       "      <td>ETF Database</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>The TDVG ETF Is a Stellar Choice for Dividend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20210104T120000</td>\n",
       "      <td>Apple Veterans’ Lidar Startup Adds $200 Millio...</td>\n",
       "      <td>Aeva, a lidar startup founded by former Apple ...</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2021-0...</td>\n",
       "      <td>Bloomberg.com</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>Apple Veterans’ Lidar Startup Adds $200 Millio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker   time_published                                              title  \\\n",
       "0   AAPL  20201229T125600  Intel shares rise after Third Point urges chip...   \n",
       "1   AAPL  20201230T052800  Apple loses copyright claims in lawsuit agains...   \n",
       "2   AAPL  20201230T022400  Exclusive: Hedge fund Third Point urges Intel ...   \n",
       "3   AAPL  20210104T212202  The TDVG ETF Is a Stellar Choice for Dividend ...   \n",
       "4   AAPL  20210104T120000  Apple Veterans’ Lidar Startup Adds $200 Millio...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hedge fund Third Point, which recently acquire...   \n",
       "1  A federal judge in Florida dismissed Apple Inc...   \n",
       "2  Activist hedge fund Third Point LLC, which has...   \n",
       "3  The TDVG ETF is highlighted as a strong option...   \n",
       "4  Aeva, a lidar startup founded by former Apple ...   \n",
       "\n",
       "                                                 url         source  \\\n",
       "0  https://www.cnbc.com/2020/12/29/third-point-ur...           CNBC   \n",
       "1  https://www.reuters.com/business/apple-loses-c...        Reuters   \n",
       "2  https://www.reuters.com/business/retail-consum...        Reuters   \n",
       "3  https://etfdb.com/active-etf-channel/tdvg-etf-...   ETF Database   \n",
       "4  https://www.bloomberg.com/news/articles/2021-0...  Bloomberg.com   \n",
       "\n",
       "        date                                               text  \n",
       "0 2020-12-29  Intel shares rise after Third Point urges chip...  \n",
       "1 2020-12-30  Apple loses copyright claims in lawsuit agains...  \n",
       "2 2020-12-30  Exclusive: Hedge fund Third Point urges Intel ...  \n",
       "3 2021-01-04  The TDVG ETF Is a Stellar Choice for Dividend ...  \n",
       "4 2021-01-04  Apple Veterans’ Lidar Startup Adds $200 Millio...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finbert_scores(texts, batch_size: int = 16, max_length: int = 256):\n",
    "    # returns np.array shape [n,3] aligned with model.config.id2label\n",
    "    probs_all = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"FinBERT\", leave=False):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch, truncation=True, padding=True, max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "            probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        probs_all.append(probs)\n",
    "    return np.vstack(probs_all) if probs_all else np.zeros((0,3), dtype=float)\n",
    "\n",
    "def build_text(row) -> str:\n",
    "    title = row.get(\"title\") or \"\"\n",
    "    summary = row.get(\"summary\") or \"\"\n",
    "    txt = (title + \". \" + summary).strip()\n",
    "    return txt[:5000]  # safety cap\n",
    "\n",
    "news = news_all.copy()\n",
    "news[\"text\"] = news.apply(build_text, axis=1)\n",
    "\n",
    "# ограничим пустые/короткие тексты\n",
    "news = news[news[\"text\"].str.len() >= 5].copy()\n",
    "news = news.sort_values([\"ticker\",\"date\",\"url\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"News rows:\", len(news))\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c1198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet engine: fastparquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/news_scored_all.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>time_published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neg</th>\n",
       "      <th>p_neu</th>\n",
       "      <th>s_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201229T125600</td>\n",
       "      <td>Intel shares rise after Third Point urges chip...</td>\n",
       "      <td>Hedge fund Third Point, which recently acquire...</td>\n",
       "      <td>https://www.cnbc.com/2020/12/29/third-point-ur...</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>Intel shares rise after Third Point urges chip...</td>\n",
       "      <td>0.375198</td>\n",
       "      <td>0.590296</td>\n",
       "      <td>0.034506</td>\n",
       "      <td>-0.215098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201230T052800</td>\n",
       "      <td>Apple loses copyright claims in lawsuit agains...</td>\n",
       "      <td>A federal judge in Florida dismissed Apple Inc...</td>\n",
       "      <td>https://www.reuters.com/business/apple-loses-c...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>Apple loses copyright claims in lawsuit agains...</td>\n",
       "      <td>0.047186</td>\n",
       "      <td>0.759848</td>\n",
       "      <td>0.192967</td>\n",
       "      <td>-0.712662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20201230T022400</td>\n",
       "      <td>Exclusive: Hedge fund Third Point urges Intel ...</td>\n",
       "      <td>Activist hedge fund Third Point LLC, which has...</td>\n",
       "      <td>https://www.reuters.com/business/retail-consum...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>Exclusive: Hedge fund Third Point urges Intel ...</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>0.936882</td>\n",
       "      <td>0.036756</td>\n",
       "      <td>-0.910520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20210104T212202</td>\n",
       "      <td>The TDVG ETF Is a Stellar Choice for Dividend ...</td>\n",
       "      <td>The TDVG ETF is highlighted as a strong option...</td>\n",
       "      <td>https://etfdb.com/active-etf-channel/tdvg-etf-...</td>\n",
       "      <td>ETF Database</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>The TDVG ETF Is a Stellar Choice for Dividend ...</td>\n",
       "      <td>0.931475</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.058486</td>\n",
       "      <td>0.921437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>20210104T120000</td>\n",
       "      <td>Apple Veterans’ Lidar Startup Adds $200 Millio...</td>\n",
       "      <td>Aeva, a lidar startup founded by former Apple ...</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2021-0...</td>\n",
       "      <td>Bloomberg.com</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>Apple Veterans’ Lidar Startup Adds $200 Millio...</td>\n",
       "      <td>0.949373</td>\n",
       "      <td>0.015201</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.934172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker   time_published                                              title  \\\n",
       "0   AAPL  20201229T125600  Intel shares rise after Third Point urges chip...   \n",
       "1   AAPL  20201230T052800  Apple loses copyright claims in lawsuit agains...   \n",
       "2   AAPL  20201230T022400  Exclusive: Hedge fund Third Point urges Intel ...   \n",
       "3   AAPL  20210104T212202  The TDVG ETF Is a Stellar Choice for Dividend ...   \n",
       "4   AAPL  20210104T120000  Apple Veterans’ Lidar Startup Adds $200 Millio...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Hedge fund Third Point, which recently acquire...   \n",
       "1  A federal judge in Florida dismissed Apple Inc...   \n",
       "2  Activist hedge fund Third Point LLC, which has...   \n",
       "3  The TDVG ETF is highlighted as a strong option...   \n",
       "4  Aeva, a lidar startup founded by former Apple ...   \n",
       "\n",
       "                                                 url         source  \\\n",
       "0  https://www.cnbc.com/2020/12/29/third-point-ur...           CNBC   \n",
       "1  https://www.reuters.com/business/apple-loses-c...        Reuters   \n",
       "2  https://www.reuters.com/business/retail-consum...        Reuters   \n",
       "3  https://etfdb.com/active-etf-channel/tdvg-etf-...   ETF Database   \n",
       "4  https://www.bloomberg.com/news/articles/2021-0...  Bloomberg.com   \n",
       "\n",
       "        date                                               text     p_pos  \\\n",
       "0 2020-12-29  Intel shares rise after Third Point urges chip...  0.375198   \n",
       "1 2020-12-30  Apple loses copyright claims in lawsuit agains...  0.047186   \n",
       "2 2020-12-30  Exclusive: Hedge fund Third Point urges Intel ...  0.026362   \n",
       "3 2021-01-04  The TDVG ETF Is a Stellar Choice for Dividend ...  0.931475   \n",
       "4 2021-01-04  Apple Veterans’ Lidar Startup Adds $200 Millio...  0.949373   \n",
       "\n",
       "      p_neg     p_neu       s_x  \n",
       "0  0.590296  0.034506 -0.215098  \n",
       "1  0.759848  0.192967 -0.712662  \n",
       "2  0.936882  0.036756 -0.910520  \n",
       "3  0.010039  0.058486  0.921437  \n",
       "4  0.015201  0.035426  0.934172  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1) Parquet safe writer (самодостаточно) ---\n",
    "_PARQUET_ENGINE = None\n",
    "try:\n",
    "    import fastparquet  # noqa: F401\n",
    "    _PARQUET_ENGINE = \"fastparquet\"\n",
    "except Exception:\n",
    "    _PARQUET_ENGINE = \"pyarrow\"\n",
    "\n",
    "def _reset_pyarrow_pandas_ext_types():\n",
    "    try:\n",
    "        import pyarrow as pa\n",
    "    except Exception:\n",
    "        return\n",
    "    for name in (\"pandas.period\", \"pandas.interval\"):\n",
    "        try:\n",
    "            pa.unregister_extension_type(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "    for attr in (\"registered_extension_types\", \"get_registered_extension_types\", \"list_registered_extension_types\"):\n",
    "        try:\n",
    "            fn = getattr(pa, attr)\n",
    "        except Exception:\n",
    "            continue\n",
    "        try:\n",
    "            reg = fn()\n",
    "            names = list(reg.keys()) if isinstance(reg, dict) else list(reg)\n",
    "            for n in names:\n",
    "                n = str(n)\n",
    "                if n.startswith(\"pandas.\"):\n",
    "                    try:\n",
    "                        pa.unregister_extension_type(n)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def safe_to_parquet(df: pd.DataFrame, path):\n",
    "    try:\n",
    "        df.to_parquet(path, index=False, engine=_PARQUET_ENGINE)\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        if (\"type extension with name pandas.\" in msg and \"already defined\" in msg) or \"ArrowKeyError\" in msg:\n",
    "            _reset_pyarrow_pandas_ext_types()\n",
    "            df.to_parquet(path, index=False, engine=_PARQUET_ENGINE)  # retry once\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "print(\"Parquet engine:\", _PARQUET_ENGINE)\n",
    "\n",
    "# --- 2) FinBERT label mapping (robust к разным вариантам id2label) ---\n",
    "id2label = {int(k): str(v).lower() for k, v in model.config.id2label.items()}\n",
    "\n",
    "pos_id = next((i for i, lab in id2label.items() if \"pos\" in lab), None)\n",
    "neg_id = next((i for i, lab in id2label.items() if \"neg\" in lab), None)\n",
    "neu_id = next((i for i, lab in id2label.items() if \"neu\" in lab), None)\n",
    "\n",
    "if pos_id is None or neg_id is None:\n",
    "    raise RuntimeError(f\"Unexpected FinBERT labels: {id2label}\")\n",
    "\n",
    "# --- 3) Готовим тексты: гарантируем str и без NaN ---\n",
    "if \"text\" not in news.columns:\n",
    "    raise RuntimeError(\"news must have a 'text' column\")\n",
    "\n",
    "texts = news[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# --- 4) Скоринг ---\n",
    "probs = finbert_scores(texts, batch_size=16, max_length=256)\n",
    "\n",
    "# probs может быть list -> в ndarray\n",
    "probs = np.asarray(probs, dtype=\"float32\")\n",
    "\n",
    "news[\"p_pos\"] = probs[:, pos_id]\n",
    "news[\"p_neg\"] = probs[:, neg_id]\n",
    "news[\"p_neu\"] = probs[:, neu_id] if neu_id is not None else np.nan\n",
    "news[\"s_x\"] = news[\"p_pos\"] - news[\"p_neg\"]\n",
    "\n",
    "# --- 5) Сохранение ---\n",
    "out_path = DATA_DIR / \"news_scored_all.parquet\"\n",
    "safe_to_parquet(news, out_path)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2afe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>I_t</th>\n",
       "      <th>n_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>-0.215098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>-0.811591</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>0.927804</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>0.254013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>0.147563</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date       I_t  n_news\n",
       "0   AAPL 2020-12-29 -0.215098       1\n",
       "1   AAPL 2020-12-30 -0.811591       2\n",
       "2   AAPL 2021-01-04  0.927804       2\n",
       "3   AAPL 2021-01-05  0.254013       3\n",
       "4   AAPL 2021-01-06  0.147563       3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Дневной индекс I_t: средний sentiment по дню (и счётчик новостей)\n",
    "daily_I = (\n",
    "    news.groupby([\"ticker\",\"date\"], as_index=False)\n",
    "        .agg(I_t=(\"s_x\",\"mean\"), n_news=(\"s_x\",\"size\"))\n",
    ")\n",
    "\n",
    "safe_to_parquet(daily_I, DATA_DIR / \"daily_sentiment_I_t.parquet\")\n",
    "daily_I.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f66906",
   "metadata": {},
   "source": [
    "## 4) Returns + RSI + MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8f8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "        date ticker        open        high         low       close  \\\n",
      "0 2020-12-28   AAPL  133.990005  137.339996  133.509995  136.690002   \n",
      "1 2020-12-29   AAPL  138.050003  138.789993  134.339996  134.869995   \n",
      "2 2020-12-30   AAPL  135.580002  135.990005  133.399994  133.720001   \n",
      "3 2020-12-31   AAPL  134.080002  134.740005  131.720001  132.690002   \n",
      "4 2021-01-04   AAPL  133.520004  133.610001  126.760002  129.410004   \n",
      "\n",
      "    adj_close       volume  \n",
      "0  133.061218  124486200.0  \n",
      "1  131.289520  121047300.0  \n",
      "2  130.170029   96452100.0  \n",
      "3  129.167374   99116600.0  \n",
      "4  125.974480  143301900.0  \n",
      "ticker\n",
      "AAPL    1256\n",
      "XOM     1256\n",
      "Name: count, dtype: Int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56316/1502786367.py:33: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  p.stack(level=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def yf_multiindex_to_long(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not isinstance(prices.columns, pd.MultiIndex):\n",
    "        raise TypeError(f\"Expected MultiIndex columns, got {type(prices.columns)}\")\n",
    "\n",
    "    p = prices.copy()\n",
    "\n",
    "    def norm(x) -> str:\n",
    "        return str(x).strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "    # 1) нормализуем имена полей (level 0) и тикеры (level 1)\n",
    "    p.columns = pd.MultiIndex.from_tuples([\n",
    "        (norm(a), str(b).strip().upper() if b is not None else \"\")\n",
    "        for a, b in p.columns\n",
    "    ])\n",
    "\n",
    "    # 2) дата: у тебя она колонкой ('date','') -> делаем индексом\n",
    "    if (\"date\", \"\") in p.columns:\n",
    "        p = p.set_index((\"date\", \"\"))\n",
    "        p.index.name = \"date\"\n",
    "    else:\n",
    "        # если даты нет колонкой, считаем что индекс и есть дата\n",
    "        p.index.name = p.index.name or \"date\"\n",
    "\n",
    "    # 3) ВАЖНО: выкидываем служебный ('ticker',''), чтобы не было конфликта при reset_index()\n",
    "    if (\"ticker\", \"\") in p.columns:\n",
    "        p = p.drop(columns=[(\"ticker\", \"\")])\n",
    "\n",
    "    # 4) stack по тикеру (level 1)\n",
    "    out = (\n",
    "        p.stack(level=1)\n",
    "         .rename_axis(index=[\"date\", \"ticker\"])\n",
    "         .reset_index()\n",
    "    )\n",
    "\n",
    "    # 5) финальная чистка\n",
    "    out.columns = [norm(c) for c in out.columns]\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out[\"ticker\"] = out[\"ticker\"].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "    # оставим основные поля, если есть\n",
    "    keep = [c for c in [\"date\",\"ticker\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"] if c in out.columns]\n",
    "    out = (\n",
    "        out[keep]\n",
    "        .dropna(subset=[\"date\",\"ticker\"])\n",
    "        .sort_values([\"ticker\",\"date\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# --- usage ---\n",
    "prices = yf_multiindex_to_long(prices)\n",
    "\n",
    "# тикеры в том же виде, что в prices\n",
    "TICKERS = [str(t).strip().upper() for t in TICKERS]\n",
    "\n",
    "print(prices.columns)\n",
    "print(prices.head())\n",
    "print(prices[\"ticker\"].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8ac94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>returns</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>MACD_hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>133.061218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>131.289520</td>\n",
       "      <td>-0.013315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.141332</td>\n",
       "      <td>-0.028266</td>\n",
       "      <td>-0.113066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>130.170029</td>\n",
       "      <td>-0.008527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.339756</td>\n",
       "      <td>-0.090564</td>\n",
       "      <td>-0.249192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>129.167374</td>\n",
       "      <td>-0.007703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.571328</td>\n",
       "      <td>-0.186717</td>\n",
       "      <td>-0.384611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>125.974480</td>\n",
       "      <td>-0.024719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000952</td>\n",
       "      <td>-0.349564</td>\n",
       "      <td>-0.651388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker   adj_close   returns  RSI      MACD  MACD_signal  \\\n",
       "0 2020-12-28   AAPL  133.061218       NaN  NaN  0.000000     0.000000   \n",
       "1 2020-12-29   AAPL  131.289520 -0.013315  0.0 -0.141332    -0.028266   \n",
       "2 2020-12-30   AAPL  130.170029 -0.008527  0.0 -0.339756    -0.090564   \n",
       "3 2020-12-31   AAPL  129.167374 -0.007703  0.0 -0.571328    -0.186717   \n",
       "4 2021-01-04   AAPL  125.974480 -0.024719  0.0 -1.000952    -0.349564   \n",
       "\n",
       "   MACD_hist  \n",
       "0   0.000000  \n",
       "1  -0.113066  \n",
       "2  -0.249192  \n",
       "3  -0.384611  \n",
       "4  -0.651388  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 0) sanity: нормализуем названия колонок (если вдруг где-то иначе) ---\n",
    "prices = prices.copy()\n",
    "prices.columns = [str(c).strip().lower().replace(\" \", \"_\") for c in prices.columns]\n",
    "\n",
    "# --- 1) выбираем правильную колонку цены для расчётов ---\n",
    "# приоритет: adj_close -> close\n",
    "price_col = \"adj_close\" if \"adj_close\" in prices.columns else (\"close\" if \"close\" in prices.columns else None)\n",
    "if price_col is None:\n",
    "    raise RuntimeError(f\"prices must contain adj_close or close. Got columns: {list(prices.columns)}\")\n",
    "\n",
    "# --- 2) индикаторы ---\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def rsi(close: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = close.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = (-delta).clip(lower=0)\n",
    "    avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()\n",
    "    rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
    "    macd_line = ema(close, fast) - ema(close, slow)\n",
    "    signal_line = ema(macd_line, signal)\n",
    "    hist = macd_line - signal_line\n",
    "    return macd_line, signal_line, hist\n",
    "\n",
    "# --- 3) Фичи по каждому тикеру ---\n",
    "feat_parts = []\n",
    "\n",
    "for t in TICKERS:\n",
    "    p = prices.loc[prices[\"ticker\"] == t].copy()\n",
    "\n",
    "    if p.empty:\n",
    "        print(f\"WARNING: no rows for {t}\")\n",
    "        continue\n",
    "\n",
    "    p = p.sort_values(\"date\")\n",
    "\n",
    "    px = pd.to_numeric(p[price_col], errors=\"coerce\")\n",
    "    p[\"returns\"] = px.pct_change()  # close-to-close\n",
    "    p[\"RSI\"] = rsi(px, period=14)\n",
    "    macd_line, signal_line, hist = macd(px)\n",
    "    p[\"MACD\"] = macd_line\n",
    "    p[\"MACD_signal\"] = signal_line\n",
    "    p[\"MACD_hist\"] = hist\n",
    "\n",
    "    feat_parts.append(p)\n",
    "\n",
    "feat_prices = pd.concat(feat_parts, ignore_index=True)\n",
    "\n",
    "# (опционально) оставим только ключевые колонки + индикаторы\n",
    "keep_cols = [c for c in [\"date\", \"ticker\", price_col, \"returns\", \"RSI\", \"MACD\", \"MACD_signal\", \"MACD_hist\"] if c in feat_prices.columns]\n",
    "feat_prices_out = feat_prices[keep_cols].copy()\n",
    "\n",
    "safe_to_parquet(feat_prices_out, DATA_DIR / \"price_features.parquet\")\n",
    "feat_prices_out.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcb8da",
   "metadata": {},
   "source": [
    "## 5) Финальная таблица `date, returns, RSI, MACD, I_t`\n",
    "\n",
    "Склеиваем price-features и `I_t` по (`ticker`, `date`). Если в какой-то день новостей нет — `I_t` будет NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7caf1983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>returns</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>I_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>50.088714</td>\n",
       "      <td>0.382271</td>\n",
       "      <td>0.438691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-12-22</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>54.443250</td>\n",
       "      <td>0.438767</td>\n",
       "      <td>0.520959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-12-23</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>57.885258</td>\n",
       "      <td>0.579341</td>\n",
       "      <td>0.630784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>57.152934</td>\n",
       "      <td>0.666920</td>\n",
       "      <td>0.534321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-12-26</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>56.727837</td>\n",
       "      <td>0.719162</td>\n",
       "      <td>0.524680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker       date   returns        RSI      MACD       I_t\n",
       "2507    XOM 2025-12-19  0.001287  50.088714  0.382271  0.438691\n",
       "2508    XOM 2025-12-22  0.012512  54.443250  0.438767  0.520959\n",
       "2509    XOM 2025-12-23  0.010749  57.885258  0.579341  0.630784\n",
       "2510    XOM 2025-12-24 -0.001675  57.152934  0.666920  0.534321\n",
       "2511    XOM 2025-12-26 -0.000923  56.727837  0.719162  0.524680"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = feat_prices.merge(daily_I[[\"ticker\",\"date\",\"I_t\"]], on=[\"ticker\",\"date\"], how=\"left\")\n",
    "\n",
    "final_small = final[[\"ticker\",\"date\",\"returns\",\"RSI\",\"MACD\",\"I_t\"]].copy()\n",
    "safe_to_parquet(final_small, DATA_DIR / \"final_features_all.parquet\")\n",
    "\n",
    "# также отдельные файлы по тикерам\n",
    "for t in TICKERS:\n",
    "    df = final_small[final_small[\"ticker\"] == t].copy()\n",
    "    safe_to_parquet(df, DATA_DIR / f\"final_features_{t}.parquet\")\n",
    "\n",
    "final_small.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
